{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17ad3ac-4eba-40e7-b8c5-6b43fc5992aa",
   "metadata": {},
   "source": [
    "# AML GReaT Synth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a49cf7-335a-4c29-9321-b1a3a4175197",
   "metadata": {},
   "source": [
    "i am using be-great==0.0.4, modified by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82828a-5665-4eb8-a234-081532e60296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from be_great import GReaT\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_NO_DUPL = False\n",
    "TRAIN_NO_STATUS = True\n",
    "CORRECT_STATUS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc510b1-027f-4497-a0bb-9a6585dc3b50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef21dcf-7834-4a9e-8d70-cf1a9740e095",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5ea34-969e-4671-99d6-ffab36a8417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# drop unnamed column (that is generated when reading)\n",
    "data = data.drop(data.columns[data.columns.str.contains('unnamed', case=False)], axis=1)\n",
    "\n",
    "# define which features not to use in training\n",
    "features_to_ignore_in_training = [\"patient_id\", \"tazi\", \"lda\", \"bayes\", \"kmeans\", \"umap\", \"kumap\"]\n",
    "if TRAIN_NO_STATUS == True:\n",
    "    features_to_ignore_in_training.append(\"status\")\n",
    "train_data = data.drop(features_to_ignore_in_training, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff40ffb-b535-4201-93ba-be95b0a8dd7a",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cece5-5a40-4049-a5c5-6345dc19fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the model\n",
    "llm = \"distilgpt2\" # name of the large language model used (see HuggingFace for more options)\n",
    "n_epochs = 25 # number of epochs to train\n",
    "save_steps=2000 # Save model weights every x steps\n",
    "experiment_dir=\"trainer\" # name of the directory where all intermediate steps are saved\n",
    "batch_size=32  # batch size\n",
    "\n",
    "# initialize the model\n",
    "great = GReaT(llm,                  \n",
    "              epochs=n_epochs,                  \n",
    "              save_steps=save_steps,               \n",
    "             logging_steps=50,             # Log the loss and learning rate every x steps\n",
    "              experiment_dir=experiment_dir, \n",
    "              batch_size=batch_size\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93708023-a6f4-40d6-ab5b-06b86321e170",
   "metadata": {},
   "source": [
    "### Training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6e5b2-3c04-45c3-8405-5887a0ecab45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = great.fit(train_data, resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94ffbd-fd7f-461e-921a-06054fe31ad6",
   "metadata": {},
   "source": [
    "### Training from a checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f3219-dbd4-4bea-99dc-71eab2f1e2d0",
   "metadata": {},
   "source": [
    "example of training from a checkpoint\n",
    "\n",
    "Note that a checkpoint will work only if the parameters of the models and train_data are the same on what the model in the checkpoint saw (except for number of epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0a433-1485-4a0c-9c2b-e79fa87f6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"trainer/checkpoint-2000\"\n",
    "# trainer = great.fit(train_data, resume_from_checkpoint=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b8b3a-3358-49ab-843e-367d65194ca3",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e889e52-dace-4805-af2e-cf3c7b824a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example I generate the model name depending on the paramaters I used for the training\n",
    "\n",
    "if TRAIN_NO_DUPL == True:\n",
    "    nodupl_flag_name = \"nodupl_\" \n",
    "else:\n",
    "    nodupl_flag_name = \"\"\n",
    "    \n",
    "if TRAIN_NO_STATUS == False:\n",
    "    status_flag_name = \"w-status_\"\n",
    "else:\n",
    "    status_flag_name = ''\n",
    "    \n",
    "# save the model for future use\n",
    "model_name = f\"{n_epochs}_epochs_{status_flag_name}noclust_{nodupl_flag_name}{llm}\"\n",
    "great.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f06aaa-fd07-47d7-8f3e-9c2865d362cc",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f21a5dd-2f36-4463-9a37-905406f36a04",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894c09c-a1d5-4229-a109-610cf919a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a previously trained model\n",
    "# model_name = \"250_epochs_noclust_distilgpt2\"\n",
    "# great = GReaT.load_from_dir(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3798c-b81b-491a-8f75-e1c06267ff42",
   "metadata": {},
   "source": [
    "## Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d83bdc-d60e-4c9c-8617-6c50fd78b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is ready to generate new samples in this way:\n",
    "n_samples = 5\n",
    "samples = great.sample(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec162d01-5fc0-4c1f-9fed-02eab53de74e",
   "metadata": {},
   "source": [
    "## Sampling 10 synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e390b2-4307-42eb-9eba-ab39e260dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing_AML_samples(samples, correct_status=False, correct_anomalous_values=False):\n",
    "    \n",
    "    '''\n",
    "    This functions performs some post processing on synthetic AML datasets produced by GReaT.\n",
    "    Converts the mutation variables into int.\n",
    "    If correct_status is True, \"status\" feature is assigned depending on \"time\": if a row has time equal to the maximum value of time,\n",
    "        sets \"status\" to 0, otherwise to 1.\n",
    "    If correct_anomalous_values is True, each value of the mutations that is not equal to 0 nor 1 is set to 1. This is because the\n",
    "        GReaT model will usually mix up similar values from different columns, or generating new values altogether; this results \n",
    "        in mutation variables sometimes assuming values slightly different from the admitted 0 or 1 (e.g.: 1.05 or 0.89). \n",
    "        This will set them always to 1 (instead of 0) based on two arguments: first, by design, the model is trained on just\n",
    "        the present mutations, so it can be safe to assume that when it produces an output regarding a mutation it is signalling\n",
    "        the presence of a mutation, not the absence of it; secondly, in the test made before writing this, the anomalous values\n",
    "        encountered were always numbers close to 1 and never close to 0.\n",
    "\n",
    "    inputs: \n",
    "        - samples (pandas.DataFrame) : the dataframe to be processed. It is expected to be a dataframe of synthetic AML data.\n",
    "        - correct_status (bool, default=False) : if True, assign \"status\" variable from \"time\"\n",
    "        - correct_anomalous_values (bool, default=False) : if True, correct anomalous values in the mutation features\n",
    "    output:\n",
    "        - samples (pandas.DataFrame) : the processed dataframe\n",
    "    '''\n",
    " \n",
    "    # all mutations names in the AML DATA\n",
    "    mutations = ['ASXL1', 'ASXL2', 'ASXL3', 'ATRX', 'BAGE3', 'BCOR', 'BRAF', 'CBFB', 'CBL', 'CDKN2A', 'CEBPA_bi', 'CEBPA_mono', 'CNTN5', 'CREBBP', 'CSF1R',\n",
    "                 'CSF3R', 'CTCF', 'CUL2', 'CUX1', 'DNMT3A', 'EED', 'ETV6', 'EZH2', 'FBXW7', 'ITD', 'FLT3_TKD', 'FLT3_other', 'GATA1', 'GATA2', 'GNAS',\n",
    "                 'GNB1', 'IDH1', 'IDH2_p.R140', 'IDH2_p.R172', 'JAK2', 'JAK3', 'KANSL1', 'KDM6A', 'KIT', 'KMT2C', 'KMT2D', 'KMT2E', 'KRAS', 'LUC7L2',\n",
    "                 'MED12', 'MLL', 'MPL', 'MYC', 'NF1', 'NFE2', 'NOTCH1', 'NPM1', 'NRAS_other', 'NRAS_p.G12_13', 'NRAS_p.Q61_62', 'PDS5B', 'PHF6', 'PPFIA2',\n",
    "                 'PRPF8', 'PTEN', 'PTPN11', 'PTPRF', 'PTPRT', 'RAD21', 'RIT1', 'RUNX1', 'S100B', 'SETBP1', 'SF1', 'SF3B1', 'SMC1A', 'SMC3', 'SMG1', 'SPP1',\n",
    "                 'SRSF2', 'STAG2', 'STAT5B', 'SUZ12', 'TET2', 'TP53', 'U2AF1', 'WT1', 'ZRSR2', 'add_8', 'add_11', 'add_13', 'add_21', 'add_22', 'del_20',\n",
    "                 'del_3', 'del_5', 'del_7', 'del_9', 'del_12', 'del_13', 'del_16', 'del_17', 'del_18', 'minusy', 't_v_11', 't_10_21', 't_12_13', 't_12_17',\n",
    "                 't_12_22', 't_13_19', 't_15_16', 't_15_17', 't_16_17', 't_16_21', 't_17_19', 't_17_21', 't_1_12', 't_1_14', 't_1_16', 't_1_17', 't_1_19',\n",
    "                 't_1_3', 't_1_4', 't_1_5', 't_1_6', 't_2_17', 't_2_3', 't_2_5', 't_2_7', 't_2_9', 't_3_16', 't_3_21', 't_3_5', 't_3_7', 't_3_9', 't_4_12',\n",
    "                 't_4_21', 't_4_9', 't_5_12', 't_5_17', 't_5_9', 't_6_9', 't_7_16', 't_7_17', 't_7_8', 't_8_10', 't_8_13', 't_8_16', 't_8_17', 't_8_21',\n",
    "                 't_9_11', 't_9_13', 't_9_17', 't_9_22', 'complex', 'others_transloc', 'inv_3', 'inv_16']\n",
    "\n",
    "     if correct_status == True:\n",
    "        # manually correct \"status\" variable, which should be completely determined by \"time\"\n",
    "        # specify the error threshold of time being equal to time_max\n",
    "        error_threshold = 10e-3\n",
    "        condition = abs(samples['time'] - samples['time'].max()) < error_threshold\n",
    "        # change values in column 'A' based on the condition\n",
    "        samples.loc[condition, 'status'] = 0\n",
    "        samples.loc[~condition, 'status'] = 1\n",
    "        \n",
    "    if correct_anomalous_values == True:\n",
    "        # correct anomlaous values\n",
    "        for index in samples.index:\n",
    "            for mutation in mutations:\n",
    "                if samples.loc[index, mutation] not in [1.0, 0.0, 1, 0, \"1\", \"0\"]: \n",
    "                    samples.loc[index, mutation] = 1\n",
    "    \n",
    "    # make sure the mutations variables are of type int\n",
    "    samples[mutations] = samples[mutations].astype('int')\n",
    "\n",
    "        \n",
    "    return samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c058c-71a7-4b7b-8df3-a5eaa2283836",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2017\n",
    "n_runs = 10\n",
    "\n",
    "for run in range(n_runs):\n",
    "    # generate a synthetic dataframe\n",
    "    samples = great.sample(n_samples)\n",
    "    # post-processing \n",
    "    samples = post_processing_AML_samples(samples, \n",
    "                                correct_status=CORRECT_STATUS, \n",
    "                                correct_anomalous_values=CORRECT_ANOMALOUS_VALUES)\n",
    "    # save the synthetic data to csv\n",
    "    samples.to_csv(f\"samples_{model_name}_run{run}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syntheticdatageneration",
   "language": "python",
   "name": "syntheticdatageneration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
